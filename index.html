<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yichao Cao</title>

    <meta name="author" content="Yichao Cao">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yichao Cao
                </p>
                <p>I am currently a Ph.D. student at Southeast University, where I also completed my master's degree under the supervision of Professor Lu Xiaobo. My research focuses on computer vision and artificial intelligence</a>.
                </p>
                <p>
                  My research interests include, but are not limited to: (1) Human-Object Interaction Detection; (2) Fine-tuning and applications of multimodal large models; (3) Embodied intelligence. Additionally, I am passionate about and eager to explore other emerging fields</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:caoyichao@seu.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="data/yichaocao-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=--8h8o0AAAAJ&hl=zh-CN&oi=ao">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Caoyichao/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/YichaoCao.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/YichaoCao.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and video understanding. Most of my research is about object detection and action detection from images and videos. Some papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- UniHOI -->
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/UniHOI.jpg'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/pdf/2208.12256.pdf">
                  <papertitle>Detecting any human-object interaction relationship: Universal hoi detector with spatial prompt learning on foundation models</papertitle>
                </a>
                <br>
                <strong>Yichao Cao</strong>, Qingfei Tang, Xiu Su, Song Chen, Shan You, Xiaobo Lu, Chang Xu
                <br>
                <em>NeurIPS</em>, 2024
                <br>
              </p>
              <div class="paper" id="bai2022masked">
                <a href="https://arxiv.org/pdf/2208.12256.pdf">paper</a> 
              </div>
            </td>
          </tr>

 
          <!-- RmLR -->
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/bai2022masked.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/pdf/2208.12256.pdf">
                  <papertitle>Re-mine, learn and reason: Exploring the cross-modal semantic correlations for language-guided hoi detection</papertitle>
                </a>
                <br>
                <strong>Yichao Cao</strong>, Qingfei Tang, Feng Yang, Xiu Su, Shan You, Xiaobo Lu, Chang Xu
                <br>
                <em>ICCV</em>, 2023
                <br>
              </p>
              <div class="paper" id="bai2022masked">
                <a href="https://arxiv.org/pdf/2208.12256.pdf">paper</a> 
              </div>
            </td>
          </tr>

 
          <!-- ACM MM -->
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/bai2022masked.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/pdf/2208.12256.pdf">
                  <papertitle>Universal Frequency Domain Perturbation for Single-Source Domain Generalization</papertitle>
                </a>
                <br>
                Chuang Liu, <strong>Yichao Cao</strong>, Haogang Zhu, Xiu Su
                <br>
                <em>ACM MM</em>, 2024
                <br>
              </p>
              <div class="paper" id="bai2022masked">
                <a href="https://arxiv.org/pdf/2208.12256.pdf">paper</a> 
              </div>
            </td>
          </tr>


 
          <!-- NIPS searching -->
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/bai2022masked.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/pdf/2208.12256.pdf">
                  <papertitle>Searching for better spatio-temporal alignment in few-shot action recognition</papertitle>
                </a>
                <br>
                <strong>Yichao Cao</strong>, Xiu Su, Qingfei Tang, Shan You, Xiaobo Lu, Chang Xu
                <br>
                <em>NeurIPS</em>, 2022
                <br>
              </p>
              <div class="paper" id="bai2022masked">
                <a href="https://arxiv.org/pdf/2208.12256.pdf">paper</a> 
              </div>
            </td>
          </tr>

 
 
          <!-- EFFNet -->
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/bai2022masked.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/pdf/2208.12256.pdf">
                  <papertitle>EFFNet: Enhanced feature foreground network for video smoke source prediction and detection</papertitle>
                </a>
                <br>
                <strong>Yichao Cao</strong>, Qingfei Tang, Xuehui Wu, Xiaobo Lu
                <br>
                <em>IEEE TCSVT</em>, 2021
                <br>
              </p>
              <div class="paper" id="bai2022masked">
                <a href="https://arxiv.org/pdf/2208.12256.pdf">paper</a> 
              </div>
            </td>
          </tr>

  
 
          <!-- Coarse2fine -->
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/bai2022masked.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/pdf/2208.12256.pdf">
                  <papertitle>Coarse2fine: local consistency aware re-prediction for weakly supervised object localization</papertitle>
                </a>
                <br>
                Yixuan Pan, Yao Yao, <strong>Yichao Cao</strong>, Chongjin Chen, Xiaobo Lu
                <br>
                <em>AAAI</em>, 2023
                <br>
              </p>
              <div class="paper" id="bai2022masked">
                <a href="https://arxiv.org/pdf/2208.12256.pdf">paper</a> 
              </div>
            </td>
          </tr>

 
  
 
          <!-- Luxin MM -->
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/bai2022masked.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/pdf/2208.12256.pdf">
                  <papertitle>Attributes grouping and mining hashing for fine-grained image retrieval</papertitle>
                </a>
                <br>
                Xin Lu, Shikun Chen, <strong>Yichao Cao</strong>, Xin Zhou, Xiaobo Lu
                <br>
                <em>ACM MM</em>, 2023
                <br>
              </p>
              <div class="paper" id="bai2022masked">
                <a href="https://arxiv.org/pdf/2208.12256.pdf">paper</a> 
              </div>
            </td>
          </tr>

  
 
          <!-- Shikun Global2Salient -->
          <tr>
            <td class="tdimg" style="padding:20px;width:35%;vertical-align:center">
              <img src='images/bai2022masked.png'>
            </td>
            <td class="tdcontent" style="padding:20px;width:65%;vertical-align:center">
              <p>
                <a href="https://arxiv.org/pdf/2208.12256.pdf">
                  <papertitle>Global2Salient: Self-adaptive feature aggregation for remote sensing smoke detection</papertitle>
                </a>
                <br>
                Shikun Chen, <strong>Yichao Cao</strong>, Xiaoqiang Feng, Xiaobo Lu
                <br>
                <em>Neurocomputing</em>, 2021
                <br>
              </p>
              <div class="paper" id="bai2022masked">
                <a href="https://arxiv.org/pdf/2208.12256.pdf">paper</a> 
              </div>
            </td>
          </tr>


            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Stolen from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>. Big thanks!
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
